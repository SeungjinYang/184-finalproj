<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Report</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2019</h1>
<h1 align="middle">Final Project: Light Field Camera</h1>
<h1 align="middle">Final Report Webpage</h1>
<h2 align="middle">Amanda Nicole, Brendan Sweeney, Seung Jin Yang</h2>

<br>

<div>

<h1>Abstract</h1>

<p>In this final project, we extended the project 3 retracer, implementing light field camera to allow post-render focusing of images. We first generated a sub-aperture images, a grid of pinhole camera renderings taken from constant lateral offset from each other. Then, we created an interactive refocuser that takes the sub-aperture images from part 1 and uses shift-and-add algorithm to display it in a GUI with an ability to toggle refocus distance.</p>
<br>
<h1>Technical Approach</h1>

<h3>•Generating sub-aperture images with a camera grid:</h3>
<p>As we were implementing a light field camera in a virtual rendering program, we decided to use the multi-camera array model instead of micron lens model. The multi-camera array model uses the fact that each sub-aperture image is equivalent to an image taken from a lateral offset away from the center of the lens, and generates sub-aperture images by taking multiple renderings of the scene with a pinhole camera taken from a grid of lateral offsets. We chose this approach in our project because:</p>
<p>a) The raytracer program already supports pinhole camera model, so generating images that are perfectly in focus is straightforward.</p>
<p>b) We don't need to worry about cross-talk or physical limitation of microns model.</p>
<p>c) The output result, multiple png files, is easier to work with than any custom format we might come up with when using micro lens model.</p>
<p>We implemented the multi-camera array by modifying project 3 code to take in additional arguments that control the number of and shifts required to produce the multi-camera array.</p>
<p>When rendering, the camera was offset to each of the positions and the rendering ran with a pinhole model to produce each sub-aperture image.</p>


<h3>•Post-rendering refocusing with shift-and-add algorithm:</h3>

<p>The paper[1] we read on computational refocusing gives us an equation,</p>

<div align = "middle">
  <img src = "equation.png" width = 500px>
</div>
<p>which shows that computational refocusing given sub-aperture images is equivalent to shifting the images and averaging their pixel values. The rate at which images are shifted is directly proportional to the distance from the center of the lens, and more shift will result in closer focus. We made a simple interactive program which calculates the distance of each sub-aperture image's camera position from the ‘center’ of the image grid, and moves the sub-aperture images towards the center appropriately. This program is capable of focusing an image at an arbitrary distance given the collection of sub-aperture images.
</p>

<h3>•Problems Encountered:</h3>
<p>We first thought of writing a single program that will handle everything from rendering to interactive display, similar to interactive mode in project 3. After working on it for a while, we decided it was a bad idea because there was a significant change required in code, and the program couldn't store intermediate results so we would have to run the code for hours before any demo could be made. We decided divide the project into two programs, one to generate sub-aperture images and one to refocus images. This allowed us to do the time-intensive part of the project (generating sub-aperture images that takes hours) and save its results, so refocusing demo can be done quickly.</p>
<p>An issue encountered and overcome when generating sub-aperture images was the need to render multiple images without user input.</p>
<p>Awaiting the completition of prior renderings was resolved by liberal use of the volatile keyword to trick the optimiser into continously check the other threads' progress.</p>

<h3>•Lessons Learned:</h3>
<p>While implementing the light field camera, we came to understand that the principle of light field camera relate closely to the notion of parallax. Take two sub-aperture images, for example. The objects far away will stay in relatively same positions in the image, while the objects close by will be further apart across the images. Therefore, averaging the images without shifting will produce an image such that the far object is overlaid correctly, while the close object is dispersed. Similarly, shifting the images toward the center before averaging will cause close objects to be overlaid correctly and vice versa. </p>
<div align="middle">
  <img src="explain.png" align="middle" width="600px"/>
</div>
<br>
<h1>Results</h1>
<h3>•Sub-aperture images:</h3>

<div align="middle">
  <table style="width=50%">
  <tr>
  <td>
    <table>
      <col width="20%">
      <tr>
        <td><img src="betterdragon/lfi00.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi10.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi20.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi30.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi40.png" align="middle" width="100px"/></td>
      </tr>
      <tr>
        <td><img src="betterdragon/lfi01.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi11.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi21.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi31.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi41.png" align="middle" width="100px"/></td>
      </tr>
      <tr>
        <td><img src="betterdragon/lfi02.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi12.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi22.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi32.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi42.png" align="middle" width="100px"/></td>
      </tr>
      <tr>
        <td><img src="betterdragon/lfi03.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi13.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi23.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi33.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi43.png" align="middle" width="100px"/></td>
      </tr>
      <tr>
        <td><img src="betterdragon/lfi04.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi14.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi24.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi34.png" align="middle" width="100px"/></td>
        <td><img src="betterdragon/lfi44.png" align="middle" width="100px"/></td>
      </tr>
    </table>
  </td>
  <td>
    <img src="betterdragon/subaperture.gif" align="middle" width="500px"/>
  </td>
  </tr>
  </table>
</div>

<h3>•Post-refocus rendering:</h3>
<div align = middle>
<iframe src="https://drive.google.com/file/d/1VBwD3l2b9skMiU0TdNz4UCFixjr3TQvh/preview" width="640" height="440"></iframe>
</div>
<br>
<h1>References</h1>
<p>[1] <a href="https://stanford.edu/class/ee367/reading/Ren%20Ng-thesis%20Lytro.pdf">Digital Light Field Photography Thesis, Ren Ng.</a></p>
<p>[2] <a href="http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/lectures/18_lfcamera.pdf">CMU lecture slides, Kayvon Fatahalian.</a></p>
<p>[3] <a href="https://pdfs.semanticscholar.org/ba85/4831600ccfe9171ede48ae350ac8df0d6af3.pdf">Paper on lens refocusing, Ren Ng and Pat Hanrahan.</a></p>
<p>[4] <a href="https://petapixel.com/2015/06/22/the-science-behind-lytros-light-field-technology-and-megaray-sensors/">Article on Light Field Cameras, Michael Archambault.</a></p>

<br>
<h1>Contributions</h1>
<p>Brendan Sweeney modified the project 3 code to be able to generate a grid of sub-aperture images.</p>
<p>Seung Jin Yang, with help of Amanda Awan, wrote the interactive refocuser.</p>
<p>Seung Jin Yang and Amanda Awan created the final report website.</p>
<p>Amanda Awan created the final project video.</p>

</div>
</body>
</html>
